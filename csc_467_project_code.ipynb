{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd # Importing the Pandas library and assigning an alias 'pd' for ease of use.\n",
        "import numpy as np # Importing the NumPy library and assigning an alias 'np' for ease of use.\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer # Importing the TfidfVectorizer class from Scikit-learn's feature_extraction.text module. Reduce the number of features in a dataset by creating new features from the existing ones\n",
        "from sklearn.naive_bayes import MultinomialNB # Importing the MultinomialNB class from Scikit-learn's naive_bayes module. Classification with discrete features (e.g., word counts for text classification)\n",
        "from sklearn.neighbors import KNeighborsClassifier # Importing the KNeighborsClassifier class from Scikit-learn's neighbors module. Algorithm that makes classifications based on data neighbors\n",
        "from sklearn.metrics.pairwise import paired_distances # Importing the paired_distances function from Scikit-learn's metrics.pairwise module. Calculates distance between instances in a feature array\n",
        "from sklearn.model_selection import train_test_split # Importing the train_test_split function from Scikit-learn's model_selection module. Split our data into train and test sets.\n",
        "from sklearn.preprocessing import LabelEncoder # Importing the LabelEncoder class from Scikit-learn's preprocessing module.  Convert categorical variables into numerical form"
      ],
      "metadata": {
        "id": "EqLSq2OFyumn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load labeled dataset\n",
        "url = \"https://raw.githubusercontent.com/amankharwal/Website-data/master/dataset.csv\" # Assigning a string containing the URL of the CSV file to the variable 'url'.\n",
        "data = pd.read_csv(url) # Using Pandas (pd) to read the CSV file from the provided URL and storing it in the variable 'data'.\n",
        "print(data.head()) # Printing the first few rows (by default, the first five rows) of the DataFrame 'data' to the console."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x72mBYtyGO6x",
        "outputId": "a2a2fd36-d02b-4f15-f30d-ac56aac60f5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                Text  language\n",
            "0  klement gottwaldi surnukeha palsameeriti ning ...  Estonian\n",
            "1  sebes joseph pereira thomas  på eng the jesuit...   Swedish\n",
            "2  ถนนเจริญกรุง อักษรโรมัน thanon charoen krung เ...      Thai\n",
            "3  விசாகப்பட்டினம் தமிழ்ச்சங்கத்தை இந்துப் பத்திர...     Tamil\n",
            "4  de spons behoort tot het geslacht haliclona en...     Dutch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename the columns if they have different capitalization\n",
        "data.rename(columns={\"Text\": \"text\", \"language\": \"language\"}, inplace=True)\n",
        "\n",
        "# Split the data into features (text) and labels (language)\n",
        "X = data['text'] # 'X' holds the text data (features)\n",
        "y = data['language'] # 'y' holds the language labels\n",
        "\n",
        "# Encode the language labels to numeric values\n",
        "label_encoder = LabelEncoder() # Initialize a LabelEncoder object\n",
        "y_encoded = label_encoder.fit_transform(y) # Use LabelEncoder to transform categorical labels ('y') into numerical values"
      ],
      "metadata": {
        "id": "iV3iqFGPGWg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a TF-IDF vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer() # Initialize a TF-IDF vectorizer object\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train) # Fit and transform the training text data (X_train) into TF-IDF features\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test) # Transform the testing text data (X_test) into TF-IDF features using the fitted TF-IDF vectorizer"
      ],
      "metadata": {
        "id": "4n2PnXwSGa2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a Multinomial Naive Bayes classifier\n",
        "naive_bayes_classifier = MultinomialNB() # Initialize a Multinomial Naive Bayes classifier object\n",
        "naive_bayes_classifier.fit(X_train_tfidf, y_train) # Fit the Multinomial Naive Bayes classifier using the TF-IDF transformed training data (X_train_tfidf)\n",
        "# and corresponding training labels (y_train)\n",
        "\n",
        "# Train a K-Nearest Neighbors classifier\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=5) # Initialize a K-Nearest Neighbors classifier object with 5 neighbors (n_neighbors=5)\n",
        "knn_classifier.fit(X_train_tfidf, y_train) # Fit the K-Nearest Neighbors classifier using the TF-IDF transformed training data (X_train_tfidf)\n",
        "# and corresponding training labels (y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "xgBBRHM3Ghec",
        "outputId": "f17c4534-ddaa-44ef-f893-18742909a89f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate accuracy for Naïve Bayes classifier\n",
        "accuracy_naive_bayes = naive_bayes_classifier.score(X_test_tfidf, y_test)\n",
        "print(f\"Accuracy of Naïve Bayes classifier: {accuracy_naive_bayes * 100:.2f}%\")\n",
        "\n",
        "# Calculate accuracy for K-Nearest Neighbors classifier\n",
        "accuracy_knn = knn_classifier.score(X_test_tfidf, y_test)\n",
        "print(f\"Accuracy of K-Nearest Neighbors classifier: {accuracy_knn * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HR7bruCujESC",
        "outputId": "937f5f5f-d8c3-4be2-adf0-a8782b2b8874"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Naïve Bayes classifier: 94.30%\n",
            "Accuracy of K-Nearest Neighbors classifier: 93.57%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to calculate Sum of Squared Differences (SSD)\n",
        "def identify_language_ssd(text):\n",
        "    text_tfidf = tfidf_vectorizer.transform([text]).toarray() # Transform the input text into TF-IDF features using the fitted TF-IDF vectorizer and convert it to a dense array\n",
        "    text_tfidf = text_tfidf[0] # Retrieve the TF-IDF features as a 1D array\n",
        "\n",
        "    ssd = np.sum((X_test_tfidf.toarray() - text_tfidf) ** 2, axis=1) # Calculate Sum of Squared Differences (SSD) between the input text and the test set\n",
        "\n",
        "    min_ssd_index = np.argmin(ssd)  # Find the index corresponding to the minimum SSD\n",
        "\n",
        "    predicted_label = y_test[min_ssd_index]  # Retrieve the predicted label using the index of the minimum SSD from the testing labels (y_test)\n",
        "    predicted_language = label_encoder.inverse_transform([predicted_label])[0] # Convert the predicted label back to the original language using the LabelEncoder\n",
        "    return predicted_language\n",
        "\n",
        "def identify_language_knn(text): # Define a function to identify language using K-Nearest Neighbors (KNN) classifier\n",
        "    text_tfidf = tfidf_vectorizer.transform([text]) # Transform the input text into TF-IDF features using the fitted TF-IDF vectorizer\n",
        "    predicted_label = knn_classifier.predict(text_tfidf) # Use the trained KNN classifier to predict the language label for the input text\n",
        "    predicted_language = label_encoder.inverse_transform(predicted_label)[0] # Convert the predicted label back to the original language using the LabelEncoder\n",
        "\n",
        "    return predicted_language"
      ],
      "metadata": {
        "id": "Z7-1dzwmGkpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = input(\"Enter the text you want to identify the language for: \") # Prompt the user to input text for language identification\n",
        "\n",
        "# Encode the language labels to numeric values\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Using Naïve Bayes\n",
        "# Predict the language of the user's input text using Naïve Bayes classifier\n",
        "identified_language_naive_bayes = label_encoder.inverse_transform(naive_bayes_classifier.predict(tfidf_vectorizer.transform([user_input])))[0]\n",
        "\n",
        "\n",
        "# Using K-Nearest Neighbors\n",
        "identified_language_knn = identify_language_knn(user_input) # Predict the language of the user's input text using the K-Nearest Neighbors (KNN) classifier\n",
        "# Using Sum of Squared Differences (SSD)\n",
        "identified_language_ssd = identify_language_ssd(user_input) # Predict the language of the user's input text using the SSD method\n",
        "\n",
        "# Check if the SSD method was able to identify the language\n",
        "if identified_language_ssd:\n",
        "    print(f\"Identified language using Sum of Squared Differences (SSD): {identified_language_ssd}\") # Print the identified language using SSD\n",
        "else:\n",
        "    print(\"Unable to identify the language using the Sum of Squared Differences (SSD).\") # If SSD method couldn't identify the language, print a message\n",
        "\n",
        "\n",
        "# Print the identified language using Naïve Bayes and KNN classifiers\n",
        "print(f\"Identified language using Naïve Bayes: {identified_language_naive_bayes}\")\n",
        "print(f\"Identified language using K-Nearest Neighbors: {identified_language_knn}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EA0Nb05cGkvg",
        "outputId": "d533ff3b-3880-448b-92d9-e14898f146f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the text you want to identify the language for: ncium kakak kelasnya kyoko sejak yuuki meminta agar sakura merahasiakan hal tersebutlah keduanya menjadi akrab yuuki pun akhirnya menyukai sakura sayangnya tidak disadari oleh sakura dan hanya aiko yang tahu karena takut dibenci sakura yuuki akhirnya menganggap sakura \"\"sahabat spesia\n",
            "Identified language using Sum of Squared Differences (SSD): Chinese\n",
            "Identified language using Naïve Bayes: Indonesian\n",
            "Identified language using K-Nearest Neighbors: Indonesian\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Link to the language dataset being used in this project.\n",
        "https://raw.githubusercontent.com/amankharwal/Website-data/master/dataset.csv"
      ],
      "metadata": {
        "id": "k3Sv08l2nmEh"
      }
    }
  ]
}